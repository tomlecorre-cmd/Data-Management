# ðŸ“ˆ Financial Data Pipeline: CAC 40 & Macro-Economics Analytics

![Python](https://img.shields.io/badge/Python-3.9+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-App-FF4B4B?style=for-the-badge&logo=streamlit)
![Pandas](https://img.shields.io/badge/Pandas-ETL_Process-150458?style=for-the-badge&logo=pandas)
![Plotly](https://img.shields.io/badge/Plotly-Interactive_Viz-3F4F75?style=for-the-badge)
![Finance](https://img.shields.io/badge/Finance-Quantitative-008000?style=for-the-badge)

> **Projet AvancÃ© de Data Management**


---

## ðŸš€ Vision du Projet & ComplexitÃ©

Ce projet est une **solution complÃ¨te d'ingÃ©nierie financiÃ¨re** conÃ§ue pour rÃ©pondre Ã  une problÃ©matique complexe : **Quantifier et visualiser l'exposition des fleurons du CAC 40 aux chocs macro-Ã©conomiques mondiaux.**

Contrairement Ã  un simple dashboard de visualisation, ce projet implÃ©mente un **Pipeline ETL (Extract, Transform, Load) automatisÃ©** capable de traiter, nettoyer et normaliser plus de **20 ans d'historique boursier** pour synchroniser des donnÃ©es hÃ©tÃ©rogÃ¨nes (Actions d'entreprises vs Indices Macro-Ã©conomiques).

### ðŸ”¥ Les DÃ©fis Techniques RelevÃ©s
1.  **Ingestion Multi-Source & Multithreading :** Extraction simultanÃ©e de flux financiers massifs via l'API Yahoo Finance (35 entreprises + 12 indicateurs macro comme le Brent, l'Or, le VIX ou les Taux US).
2.  **Feature Engineering Financier :** Transformation des prix bruts en mÃ©triques comparables :
    * *RentabilitÃ© Logarithmique* pour la stationnaritÃ©.
    * *VolatilitÃ© Glissante (Rolling Volatility)* pour l'analyse dynamique du risque.
    * *Rebasage (Base 100)* pour la comparaison visuelle d'actifs aux valorisations disparates.
3.  **Mapping Intelligent :** DÃ©veloppement d'une logique algorithmique (`graphes.py`) qui associe dynamiquement chaque entreprise Ã  son facteur d'influence principal (ex: *TotalEnergies* â†” *PÃ©trole*, *LVMH* â†” *Taux de Change*).
4.  **Analyse de DonnÃ©es Non-StructurÃ©es (NLP) :** IntÃ©gration d'un module de **Web Scraping** et de **Text Mining** pour analyser le sentiment de marchÃ© via les articles de presse financiÃ¨re en temps rÃ©el.

---

## ðŸ— Architecture & Explication des Modules

Le code est structurÃ© de maniÃ¨re modulaire pour sÃ©parer la logique de traitement (Backend) de l'interface (Frontend). Voici le rÃ´le prÃ©cis de chaque fichier du dÃ©pÃ´t :

### ðŸ“‚ 1. Le Moteur ETL : `data_management.ipynb` (ou `projet data`)
**C'est l'usine de donnÃ©es.** Ce script n'est exÃ©cutÃ© qu'une seule fois pour construire la base de donnÃ©es locale.
* **Connexion API :** Utilise `yfinance` en mode multithread pour tÃ©lÃ©charger l'historique OHLCV.
* **Nettoyage (Cleaning) :** GÃ¨re les valeurs manquantes (fill NaN) et aligne les dates (les bourses n'ont pas les mÃªmes jours fÃ©riÃ©s).
* **Calculs :** GÃ©nÃ¨re les colonnes dÃ©rivÃ©es (`Daily_Return`, `VolatilitÃ©_30j`).
* **Sortie :** Produit les fichiers CSV optimisÃ©s qui seront lus par le dashboard.

### ðŸ“‚ 2. La Logique MÃ©tier : `graphes.py`
**C'est le cerveau analytique.** Ce fichier agit comme une librairie interne pour garder le code principal propre.
* **Dictionnaire de Mapping :** Contient les rÃ¨gles mÃ©tiers (ex: Lier `BNP Paribas` aux `Taux d'intÃ©rÃªts`).
* **Fonctions de Plotting :** Contient le code `Plotly` complexe pour gÃ©nÃ©rer :
    * La FrontiÃ¨re Efficiente de Markowitz.
    * Les graphiques de CorrÃ©lation Glissante (Rolling Correlation).
    * Les rÃ©gressions linÃ©aires (Beta).

### ðŸ“‚ 3. L'Interface Utilisateur : `app.py`
**C'est la tour de contrÃ´le.** C'est le fichier exÃ©cutÃ© par Streamlit.
* **Orchestration :** Charge les donnÃ©es, affiche la barre latÃ©rale et appelle les fonctions de `graphes.py` selon les choix de l'utilisateur.
* **Module NLP :** Contient la logique de scraping (`Requests` + `BeautifulSoup`) et de gÃ©nÃ©ration de Nuage de Mots (`WordCloud`) Ã  partir d'une URL fournie par l'utilisateur.

### ðŸ“‚ 4. Gestion des DÃ©pendances : `requirements.txt`
Liste toutes les bibliothÃ¨ques nÃ©cessaires (`pandas`, `numpy`, `yfinance`, `plotly`, `streamlit`, etc.) pour assurer la reproductibilitÃ© de l'environnement sur n'importe quelle machine.

---

## ðŸ› ï¸ Stack Technique & Algorithmes (SEO)

Pour assurer la performance et la prÃ©cision financiÃ¨re, nous avons utilisÃ© les bibliothÃ¨ques et algorithmes suivants :

### ðŸ“š BibliothÃ¨ques Principales
* **Data Engineering :** `pandas` (Manipulation de SÃ©ries Temporelles), `numpy` (Calculs vectoriels).
* **Finance API :** `yfinance` (RÃ©cupÃ©ration de donnÃ©es de marchÃ©).
* **Visualisation :** `plotly.graph_objects` (Graphiques financiers interactifs), `matplotlib` (Rendu statique).
* **NLP & Scraping :** `beautifulsoup4` (Parsing HTML), `requests` (HTTP), `wordcloud` (Analyse de frÃ©quence).
* **Frontend :** `streamlit` (Framework Web).

### ðŸ§® Algorithmes & Formules
1.  **RentabilitÃ© Logarithmique (Log Returns) :** $R_t = \ln(\frac{P_t}{P_{t-1}})$
2.  **VolatilitÃ© Glissante (Rolling Volatility) :** $\sigma_{ann} = \sigma_{30d} \times \sqrt{252}$
3.  **Rebasage (Base 100) :** $P_{base} = (\frac{P_t}{P_{initial}}) \times 100$

---

## ðŸ— Architecture & Modules du Code

Le projet est segmentÃ© en 3 modules distincts respectant le principe de sÃ©paration des responsabilitÃ©s.

```mermaid
graph LR
A[Flux API Yahoo Finance] -->|Extract| B(data_management.ipynb)
B -->|Transform| C{Pandas Engine}
C -->|Nettoyage & Calculs| D[Dataframes Enrichis]
D -->|Load| E[Application Streamlit]
F[Web Articles] -->|Scraping| G[Module NLP]
G -->|Processing| E
